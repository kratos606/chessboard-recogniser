{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chessboard Image Recognition and FEN Generation with CNN Model and Gradio Interface**\n",
        "\n",
        "This notebook demonstrates a deep learning-powered chessboard image recognition system using a Convolutional Neural Network (CNN) model. The system is capable of detecting chessboard pieces from an image and generating the corresponding Forsyth-Edwards Notation (FEN) string, a standard chess notation for board positions. The notebook also showcases the seamless integration of Gradio, a user-friendly interface for deploying machine learning models.\n",
        "\n",
        "Key components include:\n",
        "- A custom CNN model designed to classify chess pieces from board images.\n",
        "- Preprocessing techniques to convert images to grayscale, apply histogram equalization, and compute gradients for line detection.\n",
        "- Use of OpenCV for image processing and Sobel kernel-based gradient calculation.\n",
        "- Functionality to extract individual chessboard tiles, classify them using the CNN model, and generate FEN strings for board representation.\n",
        "- A web interface built using Gradio that allows users to upload images of chessboards and receive FEN string predictions.\n",
        "\n",
        "By following this notebook, you will learn how to process chessboard images, perform deep learning-based classification, and generate FEN strings, all while leveraging Gradio for an interactive user experience."
      ],
      "metadata": {
        "id": "DOAbaHPzyZzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdLPaJIjwzLw"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gradio as gr\n",
        "import urllib.parse\n",
        "\n",
        "# Set device (use GPU if available, otherwise fallback to CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CNN model definition\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # First Convolutional Layer: 32 features, 5x5 kernel\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
        "        # Second Convolutional Layer: 64 features, 5x5 kernel\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(8 * 8 * 64, 1024)\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout with a probability of 0.5\n",
        "        # Output layer\n",
        "        self.fc2 = nn.Linear(1024, 13)\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # Initialize weights with truncated normal (approximate with normal and clamp)\n",
        "        nn.init.trunc_normal_(self.conv1.weight, std=0.1)\n",
        "        nn.init.constant_(self.conv1.bias, 0.1)\n",
        "        nn.init.trunc_normal_(self.conv2.weight, std=0.1)\n",
        "        nn.init.constant_(self.conv2.bias, 0.1)\n",
        "        nn.init.trunc_normal_(self.fc1.weight, std=0.1)\n",
        "        nn.init.constant_(self.fc1.bias, 0.1)\n",
        "        nn.init.trunc_normal_(self.fc2.weight, std=0.1)\n",
        "        nn.init.constant_(self.fc2.bias, 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first convolutional layer + ReLU activation\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)  # First pooling\n",
        "\n",
        "        # Apply second convolutional layer + ReLU activation\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)  # Second pooling\n",
        "\n",
        "        # Flatten the tensor\n",
        "        x = x.view(-1, 8 * 8 * 64)\n",
        "\n",
        "        # Fully connected layer + ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Apply dropout\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Output layer (no activation, as CrossEntropyLoss applies Softmax internally)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Helper function to convert label index to name\n",
        "def labelIndex2Name(label_index):\n",
        "    mapping = {\n",
        "        0: '1',   # Empty square\n",
        "        1: 'K',   # White King\n",
        "        2: 'Q',   # White Queen\n",
        "        3: 'R',   # White Rook\n",
        "        4: 'B',   # White Bishop\n",
        "        5: 'N',   # White Knight\n",
        "        6: 'P',   # White Pawn\n",
        "        7: 'k',   # Black King\n",
        "        8: 'q',   # Black Queen\n",
        "        9: 'r',   # Black Rook\n",
        "        10: 'b',  # Black Bishop\n",
        "        11: 'n',  # Black Knight\n",
        "        12: 'p'   # Black Pawn\n",
        "    }\n",
        "    return mapping.get(label_index, '?')  # '?' for unknown classes\n",
        "\n",
        "# Load the saved model\n",
        "def load_model(model_path):\n",
        "    model = CNNModel()  # Instantiate the model\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))  # Load model parameters\n",
        "    model.to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    return model\n",
        "\n",
        "# Prepare an image for prediction\n",
        "def prepare_image(image):\n",
        "    \"\"\"Prepares an image for prediction by the model\"\"\"\n",
        "    img = Image.fromarray(image).convert('L')  # Convert to grayscale\n",
        "    img = img.resize((32, 32))  # Resize to 32x32\n",
        "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension\n",
        "    img_tensor = torch.tensor(img_array, dtype=torch.float32)  # Convert to tensor\n",
        "    img_tensor = img_tensor.unsqueeze(0)  # Add batch dimension\n",
        "    return img_tensor\n",
        "\n",
        "# Predict the class of the image\n",
        "def predict_image(image_tensor, model):\n",
        "    \"\"\"Predict the class of a single image using the loaded model\"\"\"\n",
        "    image_tensor = image_tensor.to(device)  # Move image to the same device as the model\n",
        "    with torch.no_grad():  # Disable gradient computation during inference\n",
        "        outputs = model(image_tensor)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class index\n",
        "    return predicted.item()\n",
        "\n",
        "# Function to convert the board to FEN\n",
        "def generate_fen(board_matrix):\n",
        "    fen_rows = []\n",
        "    for row in board_matrix:\n",
        "        fen_row = \"\"\n",
        "        empty_count = 0\n",
        "        for cell in row:\n",
        "            if cell == '1':  # Empty square\n",
        "                empty_count += 1\n",
        "            else:\n",
        "                if empty_count > 0:\n",
        "                    fen_row += str(empty_count)\n",
        "                    empty_count = 0\n",
        "                fen_row += cell\n",
        "        if empty_count > 0:\n",
        "            fen_row += str(empty_count)\n",
        "        fen_rows.append(fen_row)\n",
        "    # Ensure ranks are ordered from 8 to 1\n",
        "    fen = \"/\".join(fen_rows) + \" w KQkq - 0 1\"  # Default values for active color, castling, en passant, etc.\n",
        "    return fen\n",
        "\n",
        "# Gradient and Line Detection Functions\n",
        "def gradientx(img):\n",
        "    # Compute gradient in x-direction using larger Sobel kernel\n",
        "    grad_x = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=31)\n",
        "    return grad_x\n",
        "\n",
        "def gradienty(img):\n",
        "    # Compute gradient in y-direction using larger Sobel kernel\n",
        "    grad_y = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=31)\n",
        "    return grad_y\n",
        "\n",
        "def checkMatch(lineset):\n",
        "    linediff = np.diff(lineset)\n",
        "    x = 0\n",
        "    cnt = 0\n",
        "    for line in linediff:\n",
        "        if abs(line - x) < 5:\n",
        "            cnt += 1\n",
        "        else:\n",
        "            cnt = 0\n",
        "            x = line\n",
        "    return cnt == 5\n",
        "\n",
        "def pruneLines(lineset, image_dim, margin=20):\n",
        "    # Remove lines near the margins\n",
        "    lineset = [x for x in lineset if x > margin and x < image_dim - margin]\n",
        "    if not lineset:\n",
        "        return lineset\n",
        "    linediff = np.diff(lineset)\n",
        "    x = 0\n",
        "    cnt = 0\n",
        "    start_pos = 0\n",
        "    for i, line in enumerate(linediff):\n",
        "        if abs(line - x) < 5:\n",
        "            cnt += 1\n",
        "            if cnt == 5:\n",
        "                end_pos = i + 2\n",
        "                return lineset[start_pos:end_pos]\n",
        "        else:\n",
        "            cnt = 0\n",
        "            x = line\n",
        "            start_pos = i\n",
        "    return lineset\n",
        "\n",
        "def skeletonize_1d(arr):\n",
        "    _arr = arr.copy()\n",
        "    for i in range(len(_arr) - 1):\n",
        "        if _arr[i] <= _arr[i + 1]:\n",
        "            _arr[i] = 0\n",
        "    for i in range(len(_arr) - 1, 0, -1):\n",
        "        if _arr[i - 1] > _arr[i]:\n",
        "            _arr[i] = 0\n",
        "    return _arr\n",
        "\n",
        "def getChessLines(hdx, hdy, hdx_thresh, hdy_thresh, image_shape):\n",
        "    # Generate Gaussian window\n",
        "    window_size = 21\n",
        "    sigma = 8.0\n",
        "    gausswin = cv2.getGaussianKernel(window_size, sigma, cv2.CV_64F)\n",
        "    gausswin = gausswin.flatten()\n",
        "    half_size = window_size // 2\n",
        "\n",
        "    # Threshold signals\n",
        "    hdx_thresh_binary = np.where(hdx > hdx_thresh, 1.0, 0.0)\n",
        "    hdy_thresh_binary = np.where(hdy > hdy_thresh, 1.0, 0.0)\n",
        "\n",
        "    # Blur signals using convolution with Gaussian window\n",
        "    blur_x = np.convolve(hdx_thresh_binary, gausswin, mode='same')\n",
        "    blur_y = np.convolve(hdy_thresh_binary, gausswin, mode='same')\n",
        "\n",
        "    # Skeletonize signals\n",
        "    skel_x = skeletonize_1d(blur_x)\n",
        "    skel_y = skeletonize_1d(blur_y)\n",
        "\n",
        "    # Find line positions\n",
        "    lines_x = np.where(skel_x > 0)[0].tolist()\n",
        "    lines_y = np.where(skel_y > 0)[0].tolist()\n",
        "\n",
        "    # Prune lines\n",
        "    lines_x = pruneLines(lines_x, image_shape[1])\n",
        "    lines_y = pruneLines(lines_y, image_shape[0])\n",
        "\n",
        "    # Check if lines match expected pattern\n",
        "    is_match = (len(lines_x) == 7) and (len(lines_y) == 7) and \\\n",
        "               checkMatch(lines_x) and checkMatch(lines_y)\n",
        "\n",
        "    return lines_x, lines_y, is_match\n",
        "\n",
        "def getChessTiles(img, lines_x, lines_y):\n",
        "    stepx = int(round(np.mean(np.diff(lines_x))))\n",
        "    stepy = int(round(np.mean(np.diff(lines_y))))\n",
        "\n",
        "    # Pad the image if necessary\n",
        "    padl_x = 0\n",
        "    padr_x = 0\n",
        "    padl_y = 0\n",
        "    padr_y = 0\n",
        "    if lines_x[0] - stepx < 0:\n",
        "        padl_x = abs(lines_x[0] - stepx)\n",
        "    if lines_x[-1] + stepx > img.shape[1] - 1:\n",
        "        padr_x = lines_x[-1] + stepx - img.shape[1] + 1\n",
        "    if lines_y[0] - stepy < 0:\n",
        "        padl_y = abs(lines_y[0] - stepy)\n",
        "    if lines_y[-1] + stepy > img.shape[0] - 1:\n",
        "        padr_y = lines_y[-1] + stepy - img.shape[0] + 1\n",
        "\n",
        "    img_padded = cv2.copyMakeBorder(img, padl_y, padr_y, padl_x, padr_x, cv2.BORDER_REPLICATE)\n",
        "\n",
        "    setsx = [lines_x[0] - stepx + padl_x] + [x + padl_x for x in lines_x] + [lines_x[-1] + stepx + padl_x]\n",
        "    setsy = [lines_y[0] - stepy + padl_y] + [y + padl_y for y in lines_y] + [lines_y[-1] + stepy + padl_y]\n",
        "\n",
        "    squares = []\n",
        "    for j in range(8):\n",
        "        for i in range(8):\n",
        "            x1 = setsx[i]\n",
        "            x2 = setsx[i + 1]\n",
        "            y1 = setsy[j]\n",
        "            y2 = setsy[j + 1]\n",
        "            # Adjust sizes to ensure squares are of equal size\n",
        "            if (x2 - x1) != stepx:\n",
        "                x2 = x1 + stepx\n",
        "            if (y2 - y1) != stepy:\n",
        "                y2 = y1 + stepy\n",
        "            square = img_padded[y1:y2, x1:x2]\n",
        "            squares.append(square)\n",
        "    return squares\n",
        "\n",
        "def process_image_and_generate_fen(image, model):\n",
        "    # Convert Gradio Image to OpenCV format\n",
        "    image = np.array(image.convert(\"RGB\"))\n",
        "    image_cv = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Preprocessing\n",
        "    equ = cv2.equalizeHist(gray)\n",
        "    norm_image = equ.astype(np.float32) / 255.0\n",
        "\n",
        "    # Compute the gradients\n",
        "    grad_x = gradientx(norm_image)\n",
        "    grad_y = gradienty(norm_image)\n",
        "\n",
        "    # Clip the gradients\n",
        "    Dx_pos = np.clip(grad_x, 0, None)\n",
        "    Dx_neg = np.clip(-grad_x, 0, None)\n",
        "    Dy_pos = np.clip(grad_y, 0, None)\n",
        "    Dy_neg = np.clip(-grad_y, 0, None)\n",
        "\n",
        "    # Compute the Hough transform\n",
        "    hough_Dx = (np.sum(Dx_pos, axis=0) * np.sum(Dx_neg, axis=0)) / (norm_image.shape[0] ** 2)\n",
        "    hough_Dy = (np.sum(Dy_pos, axis=1) * np.sum(Dy_neg, axis=1)) / (norm_image.shape[1] ** 2)\n",
        "\n",
        "    # Adaptive thresholding\n",
        "    a = 1\n",
        "    is_match = False\n",
        "    lines_x = []\n",
        "    lines_y = []\n",
        "\n",
        "    while a < 5:\n",
        "        threshold_x = np.max(hough_Dx) * (a / 5.0)\n",
        "        threshold_y = np.max(hough_Dy) * (a / 5.0)\n",
        "\n",
        "        lines_x, lines_y, is_match = getChessLines(hough_Dx, hough_Dy, threshold_x, threshold_y, norm_image.shape)\n",
        "\n",
        "        if is_match:\n",
        "            break\n",
        "        else:\n",
        "            a += 1\n",
        "\n",
        "    if not is_match:\n",
        "        print(\"Retrying with different normalization...\")\n",
        "        # Use alternative normalization\n",
        "        norm_image = gray.astype(np.float32) / 255.0\n",
        "        grad_x = gradientx(norm_image)\n",
        "        grad_y = gradienty(norm_image)\n",
        "\n",
        "        Dx_pos = np.clip(grad_x, 0, None)\n",
        "        Dx_neg = np.clip(-grad_x, 0, None)\n",
        "        Dy_pos = np.clip(grad_y, 0, None)\n",
        "        Dy_neg = np.clip(-grad_y, 0, None)\n",
        "\n",
        "        hough_Dx = (np.sum(Dx_pos, axis=0) * np.sum(Dx_neg, axis=0)) / (norm_image.shape[0] ** 2)\n",
        "        hough_Dy = (np.sum(Dy_pos, axis=1) * np.sum(Dy_neg, axis=1)) / (norm_image.shape[1] ** 2)\n",
        "\n",
        "        # Repeat the adaptive thresholding\n",
        "        a = 1\n",
        "        while a < 5:\n",
        "            threshold_x = np.max(hough_Dx) * (a / 5.0)\n",
        "            threshold_y = np.max(hough_Dy) * (a / 5.0)\n",
        "\n",
        "            lines_x, lines_y, is_match = getChessLines(hough_Dx, hough_Dy, threshold_x, threshold_y, norm_image.shape)\n",
        "\n",
        "            if is_match:\n",
        "                break\n",
        "            else:\n",
        "                a += 1\n",
        "\n",
        "    if is_match:\n",
        "        print(\"7 horizontal and vertical lines found, slicing up squares\")\n",
        "        squares = getChessTiles(gray, lines_x, lines_y)\n",
        "        print(f\"Tiles generated: ({squares[0].shape[0]}x{squares[0].shape[1]}) * {len(squares)}\")\n",
        "\n",
        "        board_matrix = [[] for _ in range(8)]  # 8x8 board\n",
        "\n",
        "        for i, square in enumerate(squares):\n",
        "            # Calculate row and column\n",
        "            row = i // 8  # Ranks 8 to 1\n",
        "            col = i % 8\n",
        "\n",
        "            # Resize to 32x32 for prediction\n",
        "            resized = cv2.resize(square, (32, 32), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            # Predict the piece on this square\n",
        "            image_tensor = prepare_image(resized)\n",
        "            predicted_class = predict_image(image_tensor, model)\n",
        "            piece = labelIndex2Name(predicted_class)\n",
        "\n",
        "            board_matrix[row].append(piece)\n",
        "\n",
        "        # Generate FEN from board_matrix\n",
        "        fen = generate_fen(board_matrix)\n",
        "        print(f\"Generated FEN: {fen}\")\n",
        "\n",
        "        return fen\n",
        "    else:\n",
        "        print(f\"No squares to save for the uploaded image.\")\n",
        "        return \"Failed to detect a valid chessboard in the image.\"\n",
        "\n",
        "# Initialize and load the model once\n",
        "MODEL_PATH = \"model_100.pth\"  # Replace with your actual model path\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"Model file '{MODEL_PATH}' not found. Please ensure the path is correct.\")\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def gradio_predict(image):\n",
        "    fen = process_image_and_generate_fen(image, model)\n",
        "    if fen.startswith(\"Failed\"):\n",
        "        # Return the error message as-is in Markdown\n",
        "        return f\"**Error:** {fen}\"\n",
        "    else:\n",
        "        # URL-encode the FEN string to ensure it's safe for URLs\n",
        "        fen_encoded = urllib.parse.quote(fen)\n",
        "\n",
        "        # Create URLs for Lichess and Chess.com analysis with the encoded FEN\n",
        "        lichess_url = f\"https://lichess.org/editor/{fen_encoded}\"\n",
        "        chesscom_url = f\"https://www.chess.com/analysis?fen={fen_encoded}\"\n",
        "\n",
        "        # Create a Markdown-formatted string with the FEN and clickable links\n",
        "        markdown_output = f\"\"\"\n",
        "            **Generated FEN:**\n",
        "            {fen}\n",
        "\n",
        "            **Analyze Your Position:**\n",
        "\n",
        "            - [🔍 Analyze on Lichess]({lichess_url})\n",
        "            - [🔍 Analyze on Chess.com]({chesscom_url})\n",
        "        \"\"\"\n",
        "        return markdown_output\n",
        "\n",
        "# Create Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_predict,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Chessboard Image\"),\n",
        "    outputs=gr.Markdown(label=\"FEN and Analysis Links\"),  # Changed from gr.Textbox to gr.Markdown\n",
        "    title=\"Chessboard to FEN Converter\",\n",
        "    description=\"Upload an image of a chessboard, and the system will generate the corresponding FEN notation along with links to analyze the position on Lichess and Chess.com.\",\n",
        "    examples=[\n",
        "        [\"example1.png\"],\n",
        "        [\"example2.png\"],\n",
        "        [\"example3.png\"]\n",
        "    ],\n",
        "    allow_flagging=\"never\"  # Optional: Disable flagging if not needed\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()"
      ]
    }
  ]
}